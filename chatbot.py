# -------------------------------------------------------------------------
# ì°¸ê³ : ì´ ì½”ë“œì˜ ì¼ë¶€ëŠ” ë‹¤ìŒ GitHub ë¦¬í¬ì§€í† ë¦¬ì—ì„œ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤:
# https://github.com/lim-hyo-jeong/Wanted-Pre-Onboarding-AI-2407
# í•´ë‹¹ ë¦¬í¬ì§€í† ë¦¬ì˜ ë¼ì´ì„¼ìŠ¤ì— ë”°ë¼ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.
# -------------------------------------------------------------------------

# Streamlit ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ê¸°íƒ€ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import streamlit as st
import time
from langchain_core.messages import HumanMessage, AIMessage
from utils import load_model, set_memory, initialize_chain, generate_message

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì œëª© ì„¤ì •
st.title("í˜ë¥´ì†Œë‚˜ ì±—ë´‡")
st.markdown("<br>", unsafe_allow_html=True)  # ë¸Œë¼ìš°ì €ì— ì¤„ ë°”ê¿ˆì„ ì‚½ì…í•©ë‹ˆë‹¤.

<<<<<<< HEAD
# ì‚¬ìš©ìë¡œë¶€í„° ìºë¦­í„°ë¥¼ ì„ íƒë°›ê¸° ìœ„í•œ ë“œë¡­ë‹¤ìš´ ë©”ë‰´ ì„¤ì •
character_name = st.selectbox(
    "**ìºë¦­í„°ë¥¼ ê³¨ë¼ì¤˜!**",
    ("baby_shark", "one_zero"),
    index=0,
    key="character_name_select",
)
# ì„ íƒëœ ìºë¦­í„° ì´ë¦„ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
st.session_state.character_name = character_name

# ì‚¬ìš©ìë¡œë¶€í„° ëª¨ë¸ì„ ì„ íƒë°›ê¸° ìœ„í•œ ë“œë¡­ë‹¤ìš´ ë©”ë‰´ ì„¤ì •
model_name = st.selectbox(
    "**ëª¨ë¸ì„ ê³¨ë¼ì¤˜!**",
    ("gpt-4o", "gpt-4-turbo", "gpt-4", "gpt-3.5-turbo"),
    index=0,
    key="model_name_select",
)
# ì„ íƒëœ ëª¨ë¸ ì´ë¦„ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
=======
character_name = st.selectbox("**ìºë¦­í„°ë¥¼ ê³¨ë¼ì¤˜!**", 
                              ("baby_shark", "one_zero"), 
                              index=0, 
                              key="character_name_select")

st.session_state.character_name = character_name

model_name = st.selectbox("**ëª¨ë¸ì„ ê³¨ë¼ì¤˜!**", 
                          ("gpt-4o", "gpt-4-turbo", "gpt-4", "gpt-3.5-turbo"), 
                          index=0, 
                          key="model_name_select")

>>>>>>> parent of dfc07c7 (ğŸ¨Ref/black formatting chatbot.py)
st.session_state.model_name = model_name

# ì„¸ì…˜ ìƒíƒœì—ì„œ ì±„íŒ… ì‹œì‘ ì—¬ë¶€ë¥¼ í™•ì¸ ë° ì´ˆê¸°í™”
if "chat_started" not in st.session_state:
    st.session_state.chat_started = False
    st.session_state.memory = None
    st.session_state.chain = None

<<<<<<< HEAD

# ì±„íŒ…ì„ ì‹œì‘í•˜ëŠ” í•¨ìˆ˜ ì •ì˜
def start_chat():
    llm = load_model(st.session_state.model_name)  # ì„ íƒëœ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    st.session_state.chat_started = True  # ì±„íŒ… ì‹œì‘ ìƒíƒœë¥¼ Trueë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
    st.session_state.memory = set_memory()  # ë©”ëª¨ë¦¬ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    st.session_state.chain = initialize_chain(
        llm, st.session_state.character_name, st.session_state.memory
    )  # ì²´ì¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

=======
def start_chat() -> None:
    """
    ì„ íƒëœ ëª¨ë¸ê³¼ ìºë¦­í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì±„íŒ…ì„ ì‹œì‘í•©ë‹ˆë‹¤.
    """
    llm = load_model(st.session_state.model_name)
    st.session_state.chat_started = True
    st.session_state.memory = set_memory()
    st.session_state.chain = initialize_chain(llm, st.session_state.character_name, st.session_state.memory)
>>>>>>> parent of dfc07c7 (ğŸ¨Ref/black formatting chatbot.py)

# "Start Chat" ë²„íŠ¼ì„ í´ë¦­í–ˆì„ ë•Œ start_chat í•¨ìˆ˜ë¥¼ í˜¸ì¶œ
if st.button("Start Chat"):
    start_chat()

st.markdown("<br>", unsafe_allow_html=True)  # ë¸Œë¼ìš°ì €ì— ì¤„ ë°”ê¿ˆì„ ì‚½ì…í•©ë‹ˆë‹¤.

# ì±„íŒ…ì´ ì‹œì‘ëœ ê²½ìš°
if st.session_state.chat_started:
    if st.session_state.memory is None or st.session_state.chain is None:
        start_chat()  # ë©”ëª¨ë¦¬ë‚˜ ì²´ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš° ë‹¤ì‹œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

    # ë©”ëª¨ë¦¬ì— ì €ì¥ëœ ëª¨ë“  ë©”ì‹œì§€ë¥¼ í™”ë©´ì— í‘œì‹œ
    for message in st.session_state.memory.chat_memory.messages:
        if isinstance(message, HumanMessage):
            role = "user"  # HumanMessageëŠ” "user" ì—­í• ë¡œ ì„¤ì •
        elif isinstance(message, AIMessage):
            role = "assistant"  # AIMessageëŠ” "assistant" ì—­í• ë¡œ ì„¤ì •
        else:
            continue
        with st.chat_message(role):  # í•´ë‹¹ ì—­í• ë¡œ ë©”ì‹œì§€ë¥¼ í™”ë©´ì— í‘œì‹œ
            st.markdown(message.content)

    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬
    if prompt := st.chat_input():
        with st.chat_message("user"):  # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ í™”ë©´ì— í‘œì‹œ
            st.markdown(prompt)

        with st.chat_message("assistant"):  # AI ì‘ë‹µì„ í™”ë©´ì— í‘œì‹œ
            message_placeholder = st.empty()  # ì‘ë‹µì„ í‘œì‹œí•  ìë¦¬ í™•ë³´
            full_response = ""
            response_content = generate_message(
                st.session_state.chain, prompt
            )  # AI ì‘ë‹µ ìƒì„±

            # ì‘ë‹µì„ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ì ì§„ì ìœ¼ë¡œ í™”ë©´ì— í‘œì‹œ
            for chunk in response_content.split():
                full_response += chunk + " "
<<<<<<< HEAD
                time.sleep(0.05)  # ê° ë‹¨ì–´ ì‚¬ì´ì— ì§€ì—°ì„ ì¶”ê°€í•˜ì—¬ ì• ë‹ˆë©”ì´ì…˜ íš¨ê³¼
                message_placeholder.markdown(full_response + "â–Œ")  # ì§„í–‰ ì¤‘ í‘œì‹œ
            message_placeholder.markdown(full_response.strip())  # ìµœì¢… ì‘ë‹µ í‘œì‹œ
=======
                time.sleep(0.05)
                message_placeholder.markdown(full_response + "â–Œ")
            message_placeholder.markdown(full_response.strip())


def load_model(model_name: str) -> ChatOpenAI:
    """
    ì£¼ì–´ì§„ ëª¨ë¸ ì´ë¦„ì„ ê¸°ë°˜ìœ¼ë¡œ ChatOpenAI ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.

    Args:
        model_name (str): ì‚¬ìš©í•  ëª¨ë¸ì˜ ì´ë¦„.

    Returns:
        ChatOpenAI: ë¡œë“œëœ ChatOpenAI ëª¨ë¸.
    """
    load_dotenv()
    
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    llm = ChatOpenAI(api_key=OPENAI_API_KEY, model_name=model_name)
    return llm 


def load_prompt(character_name: str) -> str:
    """
    ìºë¦­í„° ì´ë¦„ì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.

    Args:
        character_name (str): ìºë¦­í„°ì˜ ì´ë¦„.

    Returns:
        str: ë¡œë“œëœ í”„ë¡¬í”„íŠ¸ ë‚´ìš©.
    """
    with open(f"prompts/{character_name}.prompt", "r", encoding="utf-8") as file:
        prompt = file.read().strip()
    return prompt


def set_memory() -> ConversationBufferMemory:
    """
    ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ ë©”ëª¨ë¦¬ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.

    Returns:
        ConversationBufferMemory: ì´ˆê¸°í™”ëœ ëŒ€í™” ë©”ëª¨ë¦¬.
    """
    return ConversationBufferMemory(memory_key="chat_history", return_messages=True)


def initialize_chain(llm: ChatOpenAI, character_name: str, memory: ConversationBufferMemory) -> LLMChain:
    """
    ì£¼ì–´ì§„ LLMê³¼ ìºë¦­í„° ì´ë¦„, ë©”ëª¨ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì²´ì¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

    Args:
        llm (ChatOpenAI): ì‚¬ìš©í•  ì–¸ì–´ ëª¨ë¸.
        character_name (str): ìºë¦­í„°ì˜ ì´ë¦„.
        memory (ConversationBufferMemory): ëŒ€í™” ë©”ëª¨ë¦¬.

    Returns:
        LLMChain: ì´ˆê¸°í™”ëœ LLM ì²´ì¸.
    """
    system_prompt = load_prompt(character_name)
    custom_prompt = ChatPromptTemplate(
        messages=[
            SystemMessagePromptTemplate.from_template(system_prompt),
            MessagesPlaceholder(variable_name="chat_history"),
            HumanMessagePromptTemplate.from_template("{input}"),
        ]
    )
    chain = LLMChain(llm=llm, prompt=custom_prompt, verbose=True, memory=memory)
    return chain


def generate_message(chain: LLMChain, user_input: str) -> str:
    """
    ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ ë©”ì‹œì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        chain (LLMChain): ì‚¬ìš©í•  ì²´ì¸.
        user_input (str): ì‚¬ìš©ìì˜ ì…ë ¥.

    Returns:
        str: ìƒì„±ëœ ì‘ë‹µ ë©”ì‹œì§€.
    """
    result = chain({"input": user_input})
    response_content = result["text"]
    return response_content
>>>>>>> parent of dfc07c7 (ğŸ¨Ref/black formatting chatbot.py)
